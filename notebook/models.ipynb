{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d1cbeb",
   "metadata": {},
   "source": [
    "# first test model\n",
    "\n",
    "We try here to clasify the waves to language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4893ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d4a857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>client_id</th><th>path</th><th>language</th><th>label</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>896</td><td>&quot;/Swedish/train/swd_trn_sp_119/…</td><td>&quot;Swedish&quot;</td><td>22</td></tr><tr><td>132</td><td>&quot;/Kyrgyz/train/kyr_trn_sp_46/co…</td><td>&quot;Kyrgyz&quot;</td><td>16</td></tr><tr><td>694</td><td>&quot;/Breton/train/brt_trn_sp_83/co…</td><td>&quot;Breton&quot;</td><td>11</td></tr><tr><td>1577</td><td>&quot;/Indonesian/train/indo_trn_sp_…</td><td>&quot;Indonesian&quot;</td><td>27</td></tr><tr><td>63</td><td>&quot;/Greek/train/grk_trn_sp_25/com…</td><td>&quot;Greek&quot;</td><td>7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬─────────────────────────────────┬────────────┬───────┐\n",
       "│ client_id ┆ path                            ┆ language   ┆ label │\n",
       "│ ---       ┆ ---                             ┆ ---        ┆ ---   │\n",
       "│ i64       ┆ str                             ┆ str        ┆ i64   │\n",
       "╞═══════════╪═════════════════════════════════╪════════════╪═══════╡\n",
       "│ 896       ┆ /Swedish/train/swd_trn_sp_119/… ┆ Swedish    ┆ 22    │\n",
       "│ 132       ┆ /Kyrgyz/train/kyr_trn_sp_46/co… ┆ Kyrgyz     ┆ 16    │\n",
       "│ 694       ┆ /Breton/train/brt_trn_sp_83/co… ┆ Breton     ┆ 11    │\n",
       "│ 1577      ┆ /Indonesian/train/indo_trn_sp_… ┆ Indonesian ┆ 27    │\n",
       "│ 63        ┆ /Greek/train/grk_trn_sp_25/com… ┆ Greek      ┆ 7     │\n",
       "└───────────┴─────────────────────────────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = pl.read_csv(\"../data/train_clean.csv\").sample(fraction=1.0, shuffle=True)\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b97182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio as ta\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "MEL_TRANSFORM = T.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=64\n",
    ")\n",
    "\n",
    "class VoiceDataset(Dataset):\n",
    "    def __init__(self, df:pl.DataFrame, transform=MEL_TRANSFORM, target_sr=SAMPLE_RATE, root=\".\"):\n",
    "        self.paths = df['path']\n",
    "        self.labels = df['label']\n",
    "        self.transform = transform\n",
    "        self.target_sr = target_sr\n",
    "        self.root = root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.root + self.paths[index]\n",
    "\n",
    "        waveform, sample_rate = ta.load(path)\n",
    "        \n",
    "        if sample_rate != self.target_sr:\n",
    "            waveform = ta.functional.resample(waveform,sample_rate, self.target_sr)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(waveform)\n",
    "            features = torch.cat([features, features], dim=2)\n",
    "        else:\n",
    "            features = waveform\n",
    "\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46646621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = VoiceDataset(dfTrain, root=\"../data/common_voice_kpd\")\n",
    "\n",
    "def pad_collate(batch):\n",
    "    features = [item[0].squeeze(0).transpose(0,1) for item in batch]  # (n_mels, T) → (T, n_mels) pour LSTM\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    lengths = torch.tensor([f.shape[0] for f in features])\n",
    "\n",
    "    padded = torch.nn.utils.rnn.pad_sequence(features, batch_first=True)\n",
    "\n",
    "    return padded, torch.tensor(labels), lengths\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "622eae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22194"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98226a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "min = len(dataset[0][0][0][0])\n",
    "for i in range(22194):\n",
    "    if len(dataset[i][0][0][0]) <min:\n",
    "        min = len(dataset[i][0][0][0])\n",
    "\n",
    "print(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fafccc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 460])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d995e6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3250"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50*65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424cf4a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ebb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, root=\"\"):\n",
    "        self.paths = df[\"path\"]\n",
    "        self.labels = df[\"label\"]\n",
    "        self.root = root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sr = torchaudio.load(self.root + self.paths[idx])\n",
    "\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.functional.resample(\n",
    "                waveform, sr, SAMPLE_RATE\n",
    "            )\n",
    "\n",
    "        waveform = waveform.squeeze(0)  # [T]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "dataset = AudioDataset(dfTrain, root=\"../data/common_voice_kpd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecf19695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59136])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[260][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed861615",
   "metadata": {},
   "source": [
    "## Convolution Neural Network\n",
    "\n",
    "here we transform sequential waves to a (3250,) vector. Where we try to find a latent space for later put them in a RNN to get "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
